{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e891a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 17:44:02.801465: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/danil/Documents/Project/MemeFaceMatcher/meme-comparator/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], \"GPU\")\n",
    "import os\n",
    "import shutil\n",
    "from backend.database import Database\n",
    "from backend.face_detector import FaceDetector\n",
    "from backend.embedding_generator import EmbeddingGenerator\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea4764c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No FAISS index was found. Initializing a new one!\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/danil/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/danil/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/danil/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/danil/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/danil/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Parsing model identifier. Schema: None, Identifier: ViT-B-32\n",
      "INFO:root:Loaded built-in ViT-B-32 model config.\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/laion/CLIP-ViT-B-32-laion2B-s34B-b79K/resolve/main/open_clip_model.safetensors \"HTTP/1.1 302 Found\"\n",
      "INFO:root:Instantiating model architecture: CLIP\n",
      "INFO:root:Loading full pretrained weights from: /home/danil/.cache/huggingface/hub/models--laion--CLIP-ViT-B-32-laion2B-s34B-b79K/snapshots/1a25a446712ba5ee05982a381eed697ef9b435cf/open_clip_model.safetensors\n",
      "INFO:root:Final image preprocessing configuration set: {'size': (224, 224), 'mode': 'RGB', 'mean': (0.48145466, 0.4578275, 0.40821073), 'std': (0.26862954, 0.26130258, 0.27577711), 'interpolation': 'bicubic', 'resize_mode': 'shortest', 'fill_color': 0}\n",
      "INFO:root:Model ViT-B-32 creation process complete.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "db = Database(path='../meme_storage/db.faiss')\n",
    "fd = FaceDetector()\n",
    "eg = EmbeddingGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b433b895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m1.jpeg',\n",
       " 'm10.jpeg',\n",
       " 'm11.jpeg',\n",
       " 'm12.jpeg',\n",
       " 'm13.jpeg',\n",
       " 'm14.jpeg',\n",
       " 'm2.jpeg',\n",
       " 'm3.jpeg',\n",
       " 'm4.jpeg',\n",
       " 'm5.jpeg',\n",
       " 'm6.jpeg',\n",
       " 'm7.jpeg',\n",
       " 'm8.jpeg',\n",
       " 'm9.jpeg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originals = sorted(os.listdir('../meme_storage'))\n",
    "indexed = []\n",
    "originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce5b77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1.jpeg\n",
      "m10.jpeg\n",
      "m11.jpeg\n",
      "m12.jpeg\n",
      "m13.jpeg\n",
      "m14.jpeg\n",
      "m2.jpeg\n",
      "No faces were found!\n",
      "m3.jpeg\n",
      "m4.jpeg\n",
      "m5.jpeg\n",
      "m6.jpeg\n",
      "No faces were found!\n",
      "m7.jpeg\n",
      "m8.jpeg\n",
      "m9.jpeg\n"
     ]
    }
   ],
   "source": [
    "for file in originals:\n",
    "    print(file)\n",
    "\n",
    "    img = np.asarray(Image.open('../meme_storage/' + file))\n",
    "\n",
    "    face_data = fd.detect(img)\n",
    "    if face_data is None:\n",
    "        indexed.append(None)\n",
    "        continue\n",
    "    else:\n",
    "        cropped, emb = face_data\n",
    "\n",
    "    emb, _ = eg.generate_embedding(cropped)\n",
    "\n",
    "    indexed.append(db.add_vector(emb)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1f9f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(0),\n",
       " np.int64(1),\n",
       " np.int64(2),\n",
       " np.int64(3),\n",
       " np.int64(4),\n",
       " np.int64(5),\n",
       " None,\n",
       " np.int64(6),\n",
       " np.int64(7),\n",
       " np.int64(8),\n",
       " None,\n",
       " np.int64(9),\n",
       " np.int64(10),\n",
       " np.int64(11)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc3f4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "for original_path, id in zip(originals, indexed):\n",
    "    if id is None:\n",
    "        continue\n",
    "\n",
    "    shutil.copy('../meme_storage/' + original_path, '../meme_storage/' + str(id) + '.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8014a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del db # to save the index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
